{"ast":null,"code":"var _jsxFileName = \"/Users/ethan/Desktop/smileai/src/Camera.js\";\nimport React from 'react';\nimport 'bootstrap/dist/css/bootstrap.min.css'; //import * as blazeface from '@tensorflow-models/blazeface';\n//import '@tensorflow/tfjs-backend-webgl';\n//import * as faceapi from 'face-api.js';\n\nimport { Jumbotron, Row, Col } from 'react-bootstrap';\nimport { Button, Grid, CardMedia, CardActionArea, Card, CardActions, Box, Container, Typography } from '@material-ui/core';\nimport './styles.css';\nimport axios from 'axios';\nlet model, canvas, canvasCtx, video, newImage;\n\nclass Camera extends React.Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      video: null,\n      wait: false\n    }; //this.faceDetect = this.faceDetect.bind(this)\n    //this.drawBox = this.drawBox.bind(this)\n\n    this.sendPhoto = this.sendPhoto.bind(this);\n  }\n\n  async componentDidMount() {\n    //await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n    //console.log(faceapi.nets)\n    //model = await blazeface.load();\n    var constraints = {\n      audio: true,\n      video: {\n        width: 500,\n        height: 500\n      },\n      facingMode: {\n        exact: \"user\"\n      }\n    };\n    video = document.querySelector(\"#video\");\n    canvas = document.querySelector(\"#canvas\");\n    video.width = constraints[\"video\"][\"width\"];\n    video.height = constraints[\"video\"][\"height\"];\n    canvas.width = constraints[\"video\"][\"width\"];\n    canvas.height = constraints[\"video\"][\"height\"];\n    canvasCtx = canvas.getContext('2d');\n    canvasCtx.translate(canvas.width, 0);\n    canvasCtx.scale(-1, 1); //var loadModel = this.faceDetect;\n\n    navigator.mediaDevices.getUserMedia(constraints).then(stream => {\n      //var video = document.querySelector(\"#video\");\n      video.srcObject = stream;\n\n      video.onloadedmetadata = () => {\n        video.play();\n      }; //video.onplay = () => loadModel()\n\n    }).catch(function (err) {\n      console.log(err);\n    }); //newImage = document.createElement('img');\n    //document.body.append(newImage);\n  }\n\n  async sendPhoto() {\n    //newCtx.drawImage(canvas, canvas.width - size[0]-start[0], start[1], size[0], size[1], 0, 0, size[0],size[1])\n    canvasCtx.drawImage(video, 0, 0, 500, 500); //newImage.src = canvas.toDataURL()\n\n    await canvas.toBlob(blob => {\n      const formData = new FormData();\n      formData.append(\"image\", blob); //console.log(blob)\n\n      axios({\n        method: 'post',\n        url: 'http://127.0.0.1:8000/',\n        data: formData,\n        headers: {\n          'Content-Type': 'multipart/form-data'\n        }\n      }).then(res => {\n        var top = res.data.top;\n        var left = res.data.left;\n        var size = res.data.bottom - top;\n        canvasCtx.beginPath();\n        canvasCtx.rect(500 - size - left, top, size, size);\n        canvasCtx.strokeStyle = 'blue';\n        canvasCtx.stroke();\n        console.log(res);\n      }).catch(err => {//console.log(err)\n      });\n    });\n  }\n  /*async faceDetect() {\n  \tconst returnTensors = false;\n  \tconst predictions = await model.estimateFaces(video, returnTensors);\n  \t//const regionsToExtract = [ new faceapi.Rect(0, 0, 100, 100)]\n  \t//const predictions = await faceapi.detectAllFaces(video, new faceapi.faceRecognitionNetOptions())\n  \t//const descriptor = await faceapi.computeFaceDescriptor()\n  \t//console.log(descriptor)\n     \tawait this.drawBox(predictions)\n     \trequestAnimationFrame(this.faceDetect)\n  }\n  \tasync drawBox(predictions) {\n  \tif(predictions.length > 0) {\n  \t\tcanvasCtx.drawImage(video, 0,0)\n  \t\tfor (let i = 0; i < predictions.length; i++) {\n  \t\t\tconst start = predictions[i].topLeft;\n  \t\t\tconst end = predictions[i].bottomRight;\n  \t\t\tconst size = [end[0] - start[0], end[1] - start[1]];\n  \t\t\t// Render a bounding box over faces\n  \t\t\tcanvasCtx.beginPath();\n  \t\t\tcanvasCtx.rect(start[0], start[1], size[0], size[1]);\n  \t\t\tcanvasCtx.strokeStyle = 'black';\n  \t\t\tcanvasCtx.stroke(); \n  \t\t\tvar hidden_canvas = document.createElement('canvas');\n  \t\t\thidden_canvas.width = 720\n  \t\t\thidden_canvas.height = 500\n  \t\t\tvar newCtx = hidden_canvas.getContext('2d');\n  \t\t\t//newCtx.drawImage(canvas, canvas.width - size[0]-start[0], start[1], size[0], size[1], 0, 0, size[0],size[1])\n  \t\t\tnewCtx.drawImage(video,0,0,720,500)\n  \t\t\tnewImage.src = hidden_canvas.toDataURL()\n  \t\t\tawait hidden_canvas.toBlob((blob) => {\n  \t\t\t\tconst formData = new FormData();\n  \t\t\t\tformData.append(\"image\", blob);\n  \t\t\t\t//console.log(blob)\n  \t\t\t\taxios({\n  \t\t\t\t\t\tmethod: 'post',\n     \t\t\t\t\turl: 'http://127.0.0.1:8000/',\n     \t\t\t\t\tdata: formData,\n     \t\t\t\t\theaders: {'Content-Type': 'multipart/form-data' }\n  \t\t\t\t})\n  \t\t\t\t.then(res => {\n  \t\t\t\t\tconsole.log(res)\n  \t\t\t\t})\n  \t\t\t\t.catch(err =>{\n  \t\t\t\t\t//console.log(err)\n  \t\t\t\t})\n  \t\t\t})\n      \t}\n      }\n  }*/\n\n\n  render() {\n    return /*#__PURE__*/React.createElement(Container, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 138,\n        columnNumber: 4\n      }\n    }, /*#__PURE__*/React.createElement(Jumbotron, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 139,\n        columnNumber: 5\n      }\n    }, /*#__PURE__*/React.createElement(Row, {\n      className: \"justify-content-md-center\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 140,\n        columnNumber: 7\n      }\n    }, /*#__PURE__*/React.createElement(\"h1\", {\n      className: \"title\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 141,\n        columnNumber: 10\n      }\n    }, \"smileAI\")), /*#__PURE__*/React.createElement(Row, {\n      className: \"justify-content-md-center\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 143,\n        columnNumber: 9\n      }\n    }, /*#__PURE__*/React.createElement(\"p\", {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 144,\n        columnNumber: 9\n      }\n    }, \"Simple AI that detects smiles.\")), /*#__PURE__*/React.createElement(Row, {\n      className: \"justify-content-md-center\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 148,\n        columnNumber: 7\n      }\n    }, /*#__PURE__*/React.createElement(\"p\", {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 149,\n        columnNumber: 8\n      }\n    }, /*#__PURE__*/React.createElement(\"small\", {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 150,\n        columnNumber: 9\n      }\n    }, \"Convolutional neural network built without any deep learning libraries (only numpy).\")))), /*#__PURE__*/React.createElement(Grid, {\n      container: true,\n      direction: \"row\",\n      justify: \"center\",\n      spacing: 5,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 154,\n        columnNumber: 5\n      }\n    }, /*#__PURE__*/React.createElement(Grid, {\n      item: true,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 155,\n        columnNumber: 6\n      }\n    }, /*#__PURE__*/React.createElement(Card, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 156,\n        columnNumber: 8\n      }\n    }, /*#__PURE__*/React.createElement(CardActionArea, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 157,\n        columnNumber: 9\n      }\n    }, /*#__PURE__*/React.createElement(\"video\", {\n      id: \"video\",\n      autoPlay: true,\n      playsInline: true,\n      src: this.state.video,\n      className: \"video\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 158,\n        columnNumber: 10\n      }\n    })), /*#__PURE__*/React.createElement(CardActions, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 160,\n        columnNumber: 9\n      }\n    }, /*#__PURE__*/React.createElement(Button, {\n      onClick: this.sendPhoto,\n      variant: \"contained\",\n      color: \"primary\",\n      disabled: this.state.wait,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 161,\n        columnNumber: 10\n      }\n    }, \"Take Picture\")))), /*#__PURE__*/React.createElement(Grid, {\n      item: true,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 165,\n        columnNumber: 6\n      }\n    }, /*#__PURE__*/React.createElement(Card, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 166,\n        columnNumber: 7\n      }\n    }, /*#__PURE__*/React.createElement(CardActionArea, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 167,\n        columnNumber: 8\n      }\n    }, /*#__PURE__*/React.createElement(\"canvas\", {\n      id: \"canvas\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 168,\n        columnNumber: 9\n      }\n    }))))));\n  }\n\n}\n\nexport default Camera;","map":{"version":3,"sources":["/Users/ethan/Desktop/smileai/src/Camera.js"],"names":["React","Jumbotron","Row","Col","Button","Grid","CardMedia","CardActionArea","Card","CardActions","Box","Container","Typography","axios","model","canvas","canvasCtx","video","newImage","Camera","Component","constructor","props","state","wait","sendPhoto","bind","componentDidMount","constraints","audio","width","height","facingMode","exact","document","querySelector","getContext","translate","scale","navigator","mediaDevices","getUserMedia","then","stream","srcObject","onloadedmetadata","play","catch","err","console","log","drawImage","toBlob","blob","formData","FormData","append","method","url","data","headers","res","top","left","size","bottom","beginPath","rect","strokeStyle","stroke","render"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAO,sCAAP,C,CACA;AACA;AACA;;AACA,SAAQC,SAAR,EAAmBC,GAAnB,EAAwBC,GAAxB,QAAkC,iBAAlC;AACA,SAASC,MAAT,EAAiBC,IAAjB,EAAuBC,SAAvB,EAAkCC,cAAlC,EAAkDC,IAAlD,EAAwDC,WAAxD,EAAqEC,GAArE,EAA0EC,SAA1E,EAAqFC,UAArF,QAAsG,mBAAtG;AACA,OAAO,cAAP;AACA,OAAOC,KAAP,MAAkB,OAAlB;AACA,IAAIC,KAAJ,EAAWC,MAAX,EAAkBC,SAAlB,EAA6BC,KAA7B,EAAoCC,QAApC;;AACA,MAAMC,MAAN,SAAqBnB,KAAK,CAACoB,SAA3B,CAAoC;AACnCC,EAAAA,WAAW,CAACC,KAAD,EAAO;AACjB,UAAMA,KAAN;AACA,SAAKC,KAAL,GAAY;AACXN,MAAAA,KAAK,EAAE,IADI;AAEXO,MAAAA,IAAI,EAAE;AAFK,KAAZ,CAFiB,CAMjB;AACA;;AACA,SAAKC,SAAL,GAAiB,KAAKA,SAAL,CAAeC,IAAf,CAAoB,IAApB,CAAjB;AACA;;AACD,QAAMC,iBAAN,GAAyB;AACxB;AACA;AACA;AACG,QAAIC,WAAW,GAAG;AAAEC,MAAAA,KAAK,EAAE,IAAT;AAAeZ,MAAAA,KAAK,EAAE;AAAEa,QAAAA,KAAK,EAAE,GAAT;AAAcC,QAAAA,MAAM,EAAE;AAAtB,OAAtB;AAAkDC,MAAAA,UAAU,EAAE;AAAEC,QAAAA,KAAK,EAAE;AAAT;AAA9D,KAAlB;AACAhB,IAAAA,KAAK,GAAGiB,QAAQ,CAACC,aAAT,CAAuB,QAAvB,CAAR;AACApB,IAAAA,MAAM,GAAGmB,QAAQ,CAACC,aAAT,CAAuB,SAAvB,CAAT;AACHlB,IAAAA,KAAK,CAACa,KAAN,GAAcF,WAAW,CAAC,OAAD,CAAX,CAAqB,OAArB,CAAd;AACEX,IAAAA,KAAK,CAACc,MAAN,GAAeH,WAAW,CAAC,OAAD,CAAX,CAAqB,QAArB,CAAf;AACAb,IAAAA,MAAM,CAACe,KAAP,GAAeF,WAAW,CAAC,OAAD,CAAX,CAAqB,OAArB,CAAf;AACCb,IAAAA,MAAM,CAACgB,MAAP,GAAgBH,WAAW,CAAC,OAAD,CAAX,CAAqB,QAArB,CAAhB;AACAZ,IAAAA,SAAS,GAAGD,MAAM,CAACqB,UAAP,CAAkB,IAAlB,CAAZ;AACApB,IAAAA,SAAS,CAACqB,SAAV,CAAoBtB,MAAM,CAACe,KAA3B,EAAkC,CAAlC;AACHd,IAAAA,SAAS,CAACsB,KAAV,CAAgB,CAAC,CAAjB,EAAoB,CAApB,EAbwB,CActB;;AACCC,IAAAA,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoCb,WAApC,EACCc,IADD,CACOC,MAAD,IAAY;AACd;AACA1B,MAAAA,KAAK,CAAC2B,SAAN,GAAkBD,MAAlB;;AACA1B,MAAAA,KAAK,CAAC4B,gBAAN,GAAyB,MAAM;AAC9B5B,QAAAA,KAAK,CAAC6B,IAAN;AACA,OAFD,CAHc,CAMd;;AACF,KARF,EASEC,KATF,CASQ,UAASC,GAAT,EAAc;AAClBC,MAAAA,OAAO,CAACC,GAAR,CAAYF,GAAZ;AACA,KAXJ,EAfqB,CA2BlB;AACA;AACN;;AAED,QAAMvB,SAAN,GAAiB;AAChB;AACAT,IAAAA,SAAS,CAACmC,SAAV,CAAoBlC,KAApB,EAA0B,CAA1B,EAA4B,CAA5B,EAA8B,GAA9B,EAAkC,GAAlC,EAFgB,CAGhB;;AACA,UAAMF,MAAM,CAACqC,MAAP,CAAeC,IAAD,IAAU;AAC9B,YAAMC,QAAQ,GAAG,IAAIC,QAAJ,EAAjB;AACCD,MAAAA,QAAQ,CAACE,MAAT,CAAgB,OAAhB,EAAyBH,IAAzB,EAF6B,CAG7B;;AACAxC,MAAAA,KAAK,CAAC;AACL4C,QAAAA,MAAM,EAAE,MADH;AAEFC,QAAAA,GAAG,EAAE,wBAFH;AAGFC,QAAAA,IAAI,EAAEL,QAHJ;AAIFM,QAAAA,OAAO,EAAE;AAAC,0BAAgB;AAAjB;AAJP,OAAD,CAAL,CAMClB,IAND,CAMMmB,GAAG,IAAI;AACZ,YAAIC,GAAG,GAAGD,GAAG,CAACF,IAAJ,CAASG,GAAnB;AACA,YAAIC,IAAI,GAAGF,GAAG,CAACF,IAAJ,CAASI,IAApB;AACA,YAAIC,IAAI,GAAGH,GAAG,CAACF,IAAJ,CAASM,MAAT,GAAgBH,GAA3B;AACA9C,QAAAA,SAAS,CAACkD,SAAV;AACAlD,QAAAA,SAAS,CAACmD,IAAV,CAAe,MAAIH,IAAJ,GAASD,IAAxB,EAA6BD,GAA7B,EAAkCE,IAAlC,EAAwCA,IAAxC;AACAhD,QAAAA,SAAS,CAACoD,WAAV,GAAwB,MAAxB;AACApD,QAAAA,SAAS,CAACqD,MAAV;AACApB,QAAAA,OAAO,CAACC,GAAR,CAAYW,GAAZ;AACA,OAfD,EAgBCd,KAhBD,CAgBOC,GAAG,IAAG,CACZ;AACC,OAlBF;AAmBC,KAvBI,CAAN;AAwBA;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAqDAsB,EAAAA,MAAM,GAAE;AACP,wBACC,oBAAC,SAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC,oBAAC,SAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACE,oBAAC,GAAD;AAAK,MAAA,SAAS,EAAC,2BAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACG;AAAI,MAAA,SAAS,EAAC,OAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBADH,CADF,eAII,oBAAC,GAAD;AAAK,MAAA,SAAS,EAAC,2BAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wCADA,CAJJ,eASE,oBAAC,GAAD;AAAK,MAAA,SAAS,EAAC,2BAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8FADD,CADD,CATF,CADD,eAgBC,oBAAC,IAAD;AAAM,MAAA,SAAS,MAAf;AAAgB,MAAA,SAAS,EAAC,KAA1B;AAAgC,MAAA,OAAO,EAAC,QAAxC;AAAiD,MAAA,OAAO,EAAE,CAA1D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC,oBAAC,IAAD;AAAM,MAAA,IAAI,MAAV;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACE,oBAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC,oBAAC,cAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC;AAAO,MAAA,EAAE,EAAC,OAAV;AAAkB,MAAA,QAAQ,EAAE,IAA5B;AAAkC,MAAA,WAAW,EAAE,IAA/C;AAAqD,MAAA,GAAG,EAAE,KAAK/C,KAAL,CAAWN,KAArE;AAA4E,MAAA,SAAS,EAAC,OAAtF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADD,CADD,eAIC,oBAAC,WAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC,oBAAC,MAAD;AAAQ,MAAA,OAAO,EAAE,KAAKQ,SAAtB;AAAiC,MAAA,OAAO,EAAC,WAAzC;AAAqD,MAAA,KAAK,EAAC,SAA3D;AAAqE,MAAA,QAAQ,EAAE,KAAKF,KAAL,CAAWC,IAA1F;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBADD,CAJD,CADF,CADD,eAWC,oBAAC,IAAD;AAAM,MAAA,IAAI,MAAV;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC,oBAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC,oBAAC,cAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC;AAAQ,MAAA,EAAE,EAAC,QAAX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADD,CADD,CADD,CAXD,CAhBD,CADD;AAwCA;;AAtKkC;;AAyKpC,eAAeL,MAAf","sourcesContent":["import React from 'react';\nimport 'bootstrap/dist/css/bootstrap.min.css';\n//import * as blazeface from '@tensorflow-models/blazeface';\n//import '@tensorflow/tfjs-backend-webgl';\n//import * as faceapi from 'face-api.js';\nimport {Jumbotron, Row, Col} from 'react-bootstrap'\nimport { Button, Grid, CardMedia, CardActionArea, Card, CardActions, Box, Container, Typography} from '@material-ui/core';\nimport './styles.css';\nimport axios from 'axios';\nlet model, canvas,canvasCtx, video, newImage;\nclass Camera extends React.Component{\n\tconstructor(props){\n\t\tsuper(props);\n\t\tthis.state ={\n\t\t\tvideo: null,\n\t\t\twait: false\n\t\t}\n\t\t//this.faceDetect = this.faceDetect.bind(this)\n\t\t//this.drawBox = this.drawBox.bind(this)\n\t\tthis.sendPhoto = this.sendPhoto.bind(this)\n\t}\n\tasync componentDidMount(){\n\t\t//await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n\t\t//console.log(faceapi.nets)\n\t\t//model = await blazeface.load();\n    \tvar constraints = { audio: true, video: { width: 500, height: 500}, facingMode: { exact: \"user\" } };\n    \tvideo = document.querySelector(\"#video\");\n\t    canvas = document.querySelector(\"#canvas\");\n\t\tvideo.width = constraints[\"video\"][\"width\"];\n  \t\tvideo.height = constraints[\"video\"][\"height\"];\n  \t\tcanvas.width = constraints[\"video\"][\"width\"];\n\t    canvas.height = constraints[\"video\"][\"height\"];\n\t    canvasCtx = canvas.getContext('2d');\n\t    canvasCtx.translate(canvas.width, 0);\n\t\tcanvasCtx.scale(-1, 1);\n  \t\t//var loadModel = this.faceDetect;\n    \tnavigator.mediaDevices.getUserMedia(constraints)\n    \t.then((stream) => {\n\t        //var video = document.querySelector(\"#video\");\n\t        video.srcObject = stream;\n\t        video.onloadedmetadata = () => {\n\t        \tvideo.play();\n\t        };\n\t        //video.onplay = () => loadModel()\n     \t})\n     \t.catch(function(err) {\n        \tconsole.log(err)\n        }); \n        //newImage = document.createElement('img');\n        //document.body.append(newImage);\n\t}\n\n\tasync sendPhoto(){\t\n\t\t//newCtx.drawImage(canvas, canvas.width - size[0]-start[0], start[1], size[0], size[1], 0, 0, size[0],size[1])\n\t\tcanvasCtx.drawImage(video,0,0,500,500)\n\t\t//newImage.src = canvas.toDataURL()\n\t\tawait canvas.toBlob((blob) => {\n\t\tconst formData = new FormData();\n\t\t\tformData.append(\"image\", blob);\n\t\t\t//console.log(blob)\n\t\t\taxios({\n\t\t\t\tmethod: 'post',\n    \t\t\turl: 'http://127.0.0.1:8000/',\n    \t\t\tdata: formData,\n    \t\t\theaders: {'Content-Type': 'multipart/form-data' }\n\t\t\t})\n\t\t\t.then(res => {\n\t\t\t\tvar top = res.data.top;\n\t\t\t\tvar left = res.data.left;\n\t\t\t\tvar size = res.data.bottom-top;\n\t\t\t\tcanvasCtx.beginPath();\n\t\t\t\tcanvasCtx.rect(500-size-left,top, size, size)\n\t\t\t\tcanvasCtx.strokeStyle = 'blue';\n\t\t\t\tcanvasCtx.stroke(); \n\t\t\t\tconsole.log(res)\n\t\t\t})\n\t\t\t.catch(err =>{\n\t\t\t\t//console.log(err)\n\t\t\t\t})\n\t\t\t})\n\t}\n\n\t/*async faceDetect() {\n\t\tconst returnTensors = false;\n\t\tconst predictions = await model.estimateFaces(video, returnTensors);\n\t\t//const regionsToExtract = [ new faceapi.Rect(0, 0, 100, 100)]\n\t\t//const predictions = await faceapi.detectAllFaces(video, new faceapi.faceRecognitionNetOptions())\n\t\t//const descriptor = await faceapi.computeFaceDescriptor()\n\t\t//console.log(descriptor)\n    \tawait this.drawBox(predictions)\n    \trequestAnimationFrame(this.faceDetect)\n\t}\n\n\tasync drawBox(predictions) {\n\t\tif(predictions.length > 0) {\n\t\t\tcanvasCtx.drawImage(video, 0,0)\n\t\t\tfor (let i = 0; i < predictions.length; i++) {\n\t\t\t\tconst start = predictions[i].topLeft;\n\t\t\t\tconst end = predictions[i].bottomRight;\n\t\t\t\tconst size = [end[0] - start[0], end[1] - start[1]];\n\t\t\t\t// Render a bounding box over faces\n\t\t\t\tcanvasCtx.beginPath();\n\t\t\t\tcanvasCtx.rect(start[0], start[1], size[0], size[1]);\n\t\t\t\tcanvasCtx.strokeStyle = 'black';\n\t\t\t\tcanvasCtx.stroke(); \n\t\t\t\tvar hidden_canvas = document.createElement('canvas');\n\t\t\t\thidden_canvas.width = 720\n\t\t\t\thidden_canvas.height = 500\n\t\t\t\tvar newCtx = hidden_canvas.getContext('2d');\n\t\t\t\t//newCtx.drawImage(canvas, canvas.width - size[0]-start[0], start[1], size[0], size[1], 0, 0, size[0],size[1])\n\t\t\t\tnewCtx.drawImage(video,0,0,720,500)\n\t\t\t\tnewImage.src = hidden_canvas.toDataURL()\n\t\t\t\tawait hidden_canvas.toBlob((blob) => {\n\t\t\t\t\tconst formData = new FormData();\n\t\t\t\t\tformData.append(\"image\", blob);\n\t\t\t\t\t//console.log(blob)\n\t\t\t\t\taxios({\n\n\t\t\t\t\t\tmethod: 'post',\n    \t\t\t\t\turl: 'http://127.0.0.1:8000/',\n    \t\t\t\t\tdata: formData,\n    \t\t\t\t\theaders: {'Content-Type': 'multipart/form-data' }\n\t\t\t\t\t})\n\t\t\t\t\t.then(res => {\n\t\t\t\t\t\tconsole.log(res)\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err =>{\n\t\t\t\t\t\t//console.log(err)\n\t\t\t\t\t})\n\t\t\t\t})\n\t    \t}\n\t    }\n\t}*/\n\n\n\trender(){\n\t\treturn(\n\t\t\t<Container>\n\t\t\t\t<Jumbotron>\n\t\t\t\t\t\t<Row className=\"justify-content-md-center\">\n\t\t\t\t\t  \t\t<h1 className=\"title\">smileAI</h1>\n\t\t\t\t\t  \t</Row>\n\t\t\t\t\t  \t<Row className=\"justify-content-md-center\">\n\t\t\t\t\t\t  <p>\n\t\t\t\t\t\t    Simple AI that detects smiles.\n\t\t\t\t\t\t  </p>\n\t\t\t\t\t\t</Row>\n\t\t\t\t\t\t<Row className=\"justify-content-md-center\">\n\t\t\t\t\t\t\t<p>\n\t\t\t\t\t\t\t\t<small>Convolutional neural network built without any deep learning libraries (only numpy).</small>\n\t\t\t\t\t\t\t</p>\n\t\t\t\t\t\t</Row>\n\t\t\t\t\t</Jumbotron>\n\t\t\t\t<Grid container direction=\"row\" justify=\"center\" spacing={5}>\n\t\t\t\t\t<Grid item>\n\t\t\t\t\t\t\t<Card>\n\t\t\t\t\t\t\t\t<CardActionArea>\n\t\t\t\t\t\t\t\t\t<video id=\"video\" autoPlay={true} playsInline={true} src={this.state.video} className=\"video\"></video>\n\t\t\t\t\t\t\t\t</CardActionArea>\n\t\t\t\t\t\t\t\t<CardActions>\n\t\t\t\t\t\t\t\t\t<Button onClick={this.sendPhoto} variant=\"contained\" color=\"primary\" disabled={this.state.wait}>Take Picture</Button>\n\t\t\t\t\t\t\t\t</CardActions>\n\t\t\t\t\t\t\t</Card>\n\t\t\t\t\t</Grid>\n\t\t\t\t\t<Grid item>\n\t\t\t\t\t\t<Card>\n\t\t\t\t\t\t\t<CardActionArea>\n\t\t\t\t\t\t\t\t<canvas id=\"canvas\"></canvas>\n\t\t\t\t\t\t\t</CardActionArea>\n\t\t\t\t\t\t</Card>\n\t\t\t\t\t</Grid>\n\n\t\t\t\t</Grid>\n\t\t\t</Container>\n\n\t\t)\n\t}\n}\n\nexport default Camera;"]},"metadata":{},"sourceType":"module"}